<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML>
<HEAD>
 <META NAME="GENERATOR" CONTENT="SGML-Tools 1.0.9">
 <TITLE>Linux Benchmarking C&Oacute;MO: El Linux Benchmarking Toolkit (LBT)</TITLE>
 <LINK HREF="Benchmarking-COMO-4.html" REL=next>
 <LINK HREF="Benchmarking-COMO-2.html" REL=previous>
 <LINK HREF="Benchmarking-COMO.html#toc3" REL=contents>
</HEAD>
<BODY>
<A HREF="Benchmarking-COMO-4.html">Página siguiente</A>
<A HREF="Benchmarking-COMO-2.html">Página anterior</A>
<A HREF="Benchmarking-COMO.html#toc3">Índice general</A>
<HR>
<H2><A NAME="s3">3. El Linux Benchmarking Toolkit (LBT)</A></H2>

<P>
<P>Quiero proponer un conjunto b&aacute;sico de herramientas de medida para
Linux. Es s&oacute;lo una versi&oacute;n preliminar de un general Linux Benchmarking
Toolkit, que ser&aacute; expandido y mejorado. T&oacute;melo como lo que es,
esto es, como una propuesta. Si no cree que es un conjunto de herramientas
v&aacute;lido, sientase libre de enviarme un correo electr&oacute;nico con sus
cr&iacute;ticas y estar&eacute; encantado de hacer los cambios y mejoras, si
puedo. Sin embargo, antes de tomar una decisi&oacute;n, lea este C&Oacute;MO y las
referencias mencionadas: las cr&iacute;ticas informadas ser&aacute;n bienvenidas,
las cr&iacute;ticas sin fundamento no.
<P>
<H2><A NAME="ss3.1">3.1 Bases l&oacute;gicas</A>
</H2>

<P>
<P>&Eacute;sto es s&oacute;lo de sentido com&uacute;n:
<P>
<OL>
<LI>No debe llevar un d&iacute;a el ejecutarlo. Cuando hay que hacer tests
comparativos (varias ejecuciones), no hay nadie que est&eacute; dispuesto a
pasar d&iacute;as tratando de averiguar la mejor configuraci&oacute;n de un
sistema. Idealmente, el conjunto completo de pruebas debe llevar unos
15 minutos en una m&aacute;quina media.
</LI>
<LI>Todo el c&oacute;digo fuente de los programas de estar libremente
disponible en la Red, por razones obvias.
</LI>
<LI>Los tests deben proporcionar una representaci&oacute;n sencilla de los
resultados que refleje el rendimiento medido.
</LI>
<LI>Debe haber una mezcla de tests sint&eacute;ticos y de tests de
aplicaci&oacute;n (con resultados separados, por supuesto).
</LI>
<LI>Cada test <B>sint&eacute;tico</B> debe ejercitar un subsistema particular
hasta su m&aacute;xima capacidad.
</LI>
<LI>Los resultados de los tests <B>sint&eacute;ticos NO</B> deben mezclarse
en un s&oacute;lo resultado general (&eacute;sto acaba con la toda la idea que hay
detr&aacute;s de los tests sint&eacute;ticos, con una considerable p&eacute;rdida de
informaci&oacute;n).
</LI>
<LI>Los tests de aplicaci&oacute;n deben consistir en tareas usualmente
ejecutadas en los sistemas Linux.
</LI>
</OL>
<P>
<H2><A NAME="ss3.2">3.2 Selecci&oacute;n de herramientas</A>
</H2>

<P>
<P>He seleccionado cinco conjuntos de herramientas, tratando de evitar,
en la medida de lo posible, el solapamiento de pruebas. Son &eacute;stas:
<P>
<OL>
<LI>Compilaci&oacute;n del N&uacute;cleo 2.0.0 (con la configuraci&oacute;n por defecto)
utilizando gcc.
</LI>
<LI>La versi&oacute;n 10/03/97 de Whetstone (la &uacute;ltima que ha sacado Roy
Longbottom).
</LI>
<LI>xbench-0.2 (con los par&aacute;metros de ejecuci&oacute;n r&aacute;pida).
</LI>
<LI>La versi&oacute;n 4.01 de UnixBench (resultados parciales).
</LI>
<LI>La distribuci&oacute;n 2 de la versi&oacute;n beta de los test BYTEmark de la
revista BYTE Magazine (resultados parciales).
</LI>
</OL>
<P>Para las pruebas 4 y 5, ``(resultados parciales)'' significa que no se
tendr&aacute;n en cuenta todos los resultados producidos por estos tests.
<P>
<H2><A NAME="ss3.3">3.3 Duraci&oacute;n de las pruebas</A>
</H2>

<P>
<P>
<OL>
<LI>Compilaci&oacute;n del N&uacute;cleo 2.0.0: 5 - 30 minutos, dependiendo del
rendimiento <B>real</B> de su sistema.
</LI>
<LI>Whetstone: 100 segundos.
</LI>
<LI>Xbench-0.2: &lt; 1 hora. 
</LI>
<LI>Versi&oacute;n 4.01 de los tests UnixBench: aprox. 15 minutos.
</LI>
<LI>Los tests BYTEmark de BYTE Magazine: aprox. 10 minutos. 
</LI>
</OL>
<P>
<H2><A NAME="ss3.4">3.4 Comentarios</A>
</H2>

<P>
<H3>Compilaci&oacute;n del N&uacute;cleo 2.0.0: </H3>

<P>
<P>
<UL>
<LI><B>Qu&eacute;:</B> es el &uacute;nico test de aplicaci&oacute;n que hay en el LBT.
</LI>
<LI>El c&oacute;digo est&aacute; ampliamente difundido (finalmente he
encontrado alguna utilidad a mis viejos CD-ROMs con Linux).
</LI>
<LI>Muchos linuxeros recompilan el n&uacute;cleo a menudo, por lo que es un
medida significativa del rendimiento global del sistema.
</LI>
<LI>El n&uacute;cleo es grande y gcc utiliza una gran cantidad de memoria:
se atenua la importancia de la cach&eacute; L2.
</LI>
<LI>Hace un uso frecuente de la E/S al disco.
</LI>
<LI>Procedimiento para realizar la prueba: conseguir el c&oacute;digo de la
versi&oacute;n 2.0.0 del n&uacute;cleo, compilarlo con las opciones por defecto (make
config, pulsar Intro repetidamente). El tiempo a informar deber&iacute;a ser el
que se inverte en la compilaci&oacute;n; esto es, despu&eacute;s de que escribe make
zImage, <B>sin</B> incluir make dep, make clean. Tenga en cuenta que la
arquitectura objetivo por defecto del n&uacute;cleo es i386, de manera que si
compila en otras arquitecturas, deber&iacute;a configurar tambi&eacute;n gcc para hacer
una compilaci&oacute;n cruzada, teniendo i386 como arquitectura objetivo.
</LI>
<LI><B>Resultados: </B>tiempo de compilaci&oacute;n en minutos y segundos
(por favor, no indique las fracciones de segundo).
</LI>
</UL>
<P>
<H3>Whetstone: </H3>

<P>
<UL>
<LI><B>Qu&eacute;: </B>mide el rendimiento de punto flotante puro con un
bucle corto. El fuente (en C) es muy legible y es f&aacute;cil de ver qu&eacute;
operaciones en punto flotante intervienen.</LI>
<LI>Es la prueba m&aacute;s corta del LBT :-). </LI>
<LI>Es una prueba "Cl&aacute;sica": hay disponibles cifras comparativas, sus
defectos y deficiencias son bien conocidos.</LI>
<LI>Procedimiento para realizar la prueba: se deber&iacute;a obtener el c&oacute;digo
en C m&aacute;s reciente del sitio de Aburto. Compile y ejecute en modo de doble
precisi&oacute;n. Especifique gcc y -O2 como opciones de precompilador y
compilador, y defina POSIX 1 para especificar el tipo de m&aacute;quina.</LI>
<LI><B>Resultados: </B>una cifra del rendimiento de punto flotante en
MWIPS.</LI>
</UL>
<H3>Xbench-0.2: </H3>

<P>
<UL>
<LI><B>Qu&eacute;:</B> mide el rendimiento del servidor X.</LI>
<LI>La medida xStones proporcionada por xbench es una media ponderada de
varias pruebas referidas a una vieja estaci&oacute;n Sun con una pantalla de un
solo bit de profundidad. Hmmm... es cuestionable como test para servidores
X modernos, pero sigue siendo la mejor herramienta que he encontrado.</LI>
<LI>Procedimiento para realizar la prueba: compilar con -O2.
Especificamos unas pocas opciones para una ejecuci&oacute;n m&aacute;s r&aacute;pida:<CODE>./xbench -timegoal 3 &gt; results/name_of_your_linux_box.out</CODE>. Para
obtener la calificaci&oacute;n xStones, debemos ejecutar un gui&oacute;n (script) en
awk; la manera m&aacute;s r&aacute;pida es escribir <CODE>make summary.ms</CODE>. Compruebe
el fichero summary.ms: la calificaci&oacute;n xStone de su sistema est&aacute; en la
&uacute;ltima columna del rengl&oacute;n que tiene el nombre de su m&aacute;quina que
especific&oacute; durante la prueba.</LI>
<LI><B>Resultados:</B> una figure del rendimiento de X en xStones.</LI>
<LI>Nota: esta prueba, tal como est&aacute;, es obsoleta. Deber&iacute;a ser
reescrita.</LI>
</UL>
<H3>UnixBench versi&oacute;n 4.01: </H3>

<P>
<UL>
<LI><B>Qu&eacute;:</B> mide el rendimiento global de Unix. Esta prueba
ejercitar&aacute; el rendimiento de E/S de ficheros y multitarea del n&uacute;cleo.</LI>
<LI>He descartado los resultados de todas las pruebas aritm&eacute;ticas,
qued&aacute;ndome s&oacute;lo con los resultados relacionados con el sistema.</LI>
<LI>Procedimiento para realizar la prueba: compilar con -O2. Ejecutar
con <CODE> ./Run -1</CODE> (ejecutar cada prueba una vez). Encontrar&aacute; los
resultados en el fichero ./results/report. Calcule la media geom&eacute;trica de
los &iacute;ndices EXECL THROUGHPUT, FILECOPY 1, 2, 3, PIPE THROUGHPUT,
PIPE-BASED CONTEXT SWITCHING, PROCESS CREATION, SHELL SCRIPTS y SYSTEM
CALL OVERHEAD.</LI>
<LI><B>Resultados:</B> un &iacute;ndice del sistema.</LI>
</UL>
<H3>Banco de pruebas BYTEmark de BYTE Magazine BYTEmark: </H3>

<P>
<UL>
<LI><B>Qu&eacute;:</B> proporciona una buena medida del rendimiento de la
CPU. Aqu&iacute; hay un extracto de la documentaci&oacute;n: <EM>"Estas pruebas est&aacute;n
pensadas para exponer el l&iacute;mite superior te&oacute;rico de la arquitectura de
CPU, FPU y memoria de un sistema. No pueden medir transferencias de v&iacute;deo,
disco o red (&eacute;stos son dominios de un conjunto de pruebas diferentes).
Deber&iacute;a usted, por lo tanto, utilizar los resultados de estas pruebas como
parte, no como un todo, en cualquier evaluaci&oacute;n de un sistema."</EM></LI>
<LI>He descartado los resultados de la prueba de FPU ya que la prueba
Whetstone es representativa del rendimiento de la FPU.</LI>
<LI>He dividido las pruebas de enteros en dos grupos: aquellos m&aacute;s
representativos del rendimiento memoria-cach&eacute;-CPU y las pruebas de enteros
de la CPU.</LI>
<LI>Procedimiento para realizar la prueba: compilar con -O2. Ejecutar la
prueba con <CODE>./nbench &gt; myresults.dat</CODE> o similar. Entonces, de
myresults.dat, calcule la media geom&eacute;trica de los &iacute;ndices de las pruebas
STRING SORT, ASSIGNMENT y BITFIELD; &eacute;ste es el <B>&iacute;ndice de la
memoria</B>; calcule la media geom&eacute;trica de los &iacute;ndices de las pruebas
NUMERIC SORT, IDEA, HUFFMAN y FP EMULATION; &eacute;ste es el <B>&iacute;ndice de
enteros</B>.</LI>
<LI><B>Resultados:</B> un &iacute;ndice de memoria y un &iacute;ndice de enteros
calculado tal como se explica anteriormente.</LI>
</UL>
<H2><A NAME="ss3.5">3.5 Posibles mejoras</A>
</H2>

<P>
<P>El conjunto ideal de pruebas deber&iacute;a ejecutarse en pocos minutos, con
pruebas sint&eacute;ticas que examinen cada subsistema por separado y pruebas de
aplicaci&oacute;n que den resultados para diferentes aplicaciones. Tambi&eacute;n
deber&iacute;a generar de forma autom&aacute;tica un informe completo y quiz&aacute; enviarlo
por correo a la base de datos central en la Web.
<P>No estamos interesados en la portabilidad, pero deber&iacute;a al menos poder ser
ejecutado en cualquier versi&oacute;n reciente (&gt; 2.0.0) y 'sabor' (i386,
Alpha, Sparc...) de Linux.
<P>Si alguien tiene alguna idea al respecto de probar la red de una manera
sencilla, f&aacute;cil y fiable, con una prueba corta (menos de 30 minutos en
configuraci&oacute;n y ejecuci&oacute;n), por favor, p&oacute;ngase en contacto conmigo.
<P>
<H2><A NAME="ss3.6">3.6 El formulario de informe LBT</A>
</H2>

<P>Aparte de las pruebas, el procedimiento de 'benchmarking' no estar&iacute;a
completo sin un formulario describiendo la configuraci&oacute;n, de manera que
aqu&iacute; est&aacute; (siguiendo la gu&iacute;a de comp.benchmarks.faq):
<P>
<HR>
<PRE>
LINUX BENCHMARKING TOOLKIT REPORT FORM
</PRE>
<HR>

<HR>
<PRE>
CPU 
== 
Vendor: 
Model: 
Core clock: 
Motherboard vendor: 
Mbd. model: 
Mbd. chipset: 
Bus type: 
Bus clock: 
Cache total: 
Cache type/speed: 
SMP (number of processors): 
</PRE>
<HR>

<HR>
<PRE>
RAM 
==== 
Total: 
Type: 
Speed: 
</PRE>
<HR>

<HR>
<PRE>
Disk 
==== 
Vendor: 
Model: 
Size: 
Interface: 
Driver/Settings: 
</PRE>
<HR>

<HR>
<PRE>
Video board 
=========== 
Vendor: 
Model: 
Bus:
Video RAM type: 
Video RAM total: 
X server vendor: 
X server version: 
X server chipset choice: 
Resolution/vert. refresh rate: 
Color depth: 
</PRE>
<HR>

<HR>
<PRE>
Kernel 
===== 
Version: 
Swap size:
</PRE>
<HR>

<HR>
<PRE>
gcc 
=== 
Version: 
Options: 
libc version: 
</PRE>
<HR>

<HR>
<PRE>
Test notes 
==========
</PRE>
<HR>

<HR>
<PRE>
RESULTS 
======== 
Linux kernel 2.0.0 Compilation Time: (minutes and seconds) 
Whetstones: results are in MWIPS. 
Xbench: results are in xstones. 
Unixbench Benchmarks 4.01 system INDEX:  
BYTEmark integer INDEX:
BYTEmark memory INDEX:
</PRE>
<HR>

<HR>
<PRE>
Comments* 
========= 
* Este campo se incluye para una posible interpretaci&oacute;n de los resultados,
y como tal, es opcional. Podr&iacute;a ser la parte m&aacute;s significativa del
informe, sin embargo, especialmente si est&aacute; haciendo pruebas comparativas.
</PRE>
<HR>
<H2><A NAME="ss3.7">3.7 Pruebas del rendimiento de la red</A>
</H2>

<P>Probar el rendimiento de una red es un reto, ya que implica al menos tener
dos m&aacute;quinas, un servidor y un cliente, y por lo tanto el doble de tiempo
para configurar, m&aacute;s variables a controlar, etc... En una red ethernet,
pienso que su mejor apuesta ser&iacute;a el paquete ttcp. (por expandir)
<P>
<H2><A NAME="ss3.8">3.8 Pruebas SMP</A>
</H2>

<P>
<P>Las pruebas SMP son otro reto, y cualquier banco de pruebas dise&ntilde;ado
espec&iacute;ficamente para probar SMP tendr&aacute; dificultades prob&aacute;ndose a s&iacute; misma
en configuraciones de la vida real, ya que los algoritmos que pueden tomar
ventaja de SMP son dif&iacute;ciles de realizar. Parece que las &uacute;ltimas versiones
del n&uacute;cleo de Linux (&gt; 2.1.30 o por ah&iacute;) har&aacute;n multiproceso "muy
granulado" (<EM>fine-grained</EM>), pero no tengo m&aacute;s informaci&oacute;n al
respecto ahora mismo.
<P>Seg&uacute;n David Niemi, <EM>" ... shell8 </EM>[parte del Unixbench
4.01]<EM>hace un buen trabajo comparando hardware similare en los modos
SMP y UP."</EM>
<P>
<HR>
<A HREF="Benchmarking-COMO-4.html">Página siguiente</A>
<A HREF="Benchmarking-COMO-2.html">Página anterior</A>
<A HREF="Benchmarking-COMO.html#toc3">Índice general</A>
</BODY>
</HTML>
